{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XkrRb687ofZA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chargement du jeu de données MNIST depuis TensorFlow Datasets.**"
      ],
      "metadata": {
        "id": "9tjiESomVm7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist', split=['train', 'test'], as_supervised=True, with_info=True\n",
        ")"
      ],
      "metadata": {
        "id": "24jVVl8Io9EB",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonction de prétraitement des données :\n",
        "\n",
        "\n",
        "*   Convertit l'image en float32 et normalise les pixels (valeurs entre 0.0 et 1.0).\n",
        "*   Transforme l'image 2D (28x28) en vecteur 1D (784).\n",
        "\n"
      ],
      "metadata": {
        "id": "2fVsHUMLV0aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return tf.reshape(image, [-1]), label"
      ],
      "metadata": {
        "id": "_Gwb596Ao_sI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prétraitement des données et regroupement en mini-batchs de 64 exemples.**"
      ],
      "metadata": {
        "id": "q09YDKkVWqE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = ds_train.map(preprocess).batch(64)\n",
        "ds_test = ds_test.map(preprocess).batch(64)"
      ],
      "metadata": {
        "id": "AXeRJKIOpCEI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialisation des poids et biais du modèle :\n",
        "\n",
        "*   W1, b1 : pour la couche cachée.\n",
        "*   W2, b2 : pour la couche de sortie.\n",
        "\n"
      ],
      "metadata": {
        "id": "dU4nE4FTW3Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = tf.Variable(tf.random.normal([784, 128], stddev=0.1))\n",
        "b1 = tf.Variable(tf.zeros([128]))\n",
        "W2 = tf.Variable(tf.random.normal([128, 10], stddev=0.1))\n",
        "b2 = tf.Variable(tf.zeros([10]))"
      ],
      "metadata": {
        "id": "J4_fzuFEpE2A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Définition du modèle :\n",
        "\n",
        "\n",
        "*   Couche cachée avec ReLU.\n",
        "*   Couche de sortie produisant les logits.\n",
        "\n"
      ],
      "metadata": {
        "id": "kPs7PyJNXT9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "    x = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
        "    return tf.matmul(x, W2) + b2"
      ],
      "metadata": {
        "id": "fk3ugkkcpH8g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**La fonction de perte intègre le softmax en interne grâce à `from_logits=True`**"
      ],
      "metadata": {
        "id": "aWhBPQumYC7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.optimizers.Adam(0.001)"
      ],
      "metadata": {
        "id": "jthJal1HpK14"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Phase d'entrainement**"
      ],
      "metadata": {
        "id": "Sbb3aity5xwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for x_batch, y_batch in ds_train:\n",
        "        #  Démarrage de l'enregistrement automatique des opérations pour le calcul des gradients\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch)\n",
        "            loss = loss_fn(y_batch, logits)\n",
        "        # Calcul des gradients de la perte par rapport aux paramètres du modèle\n",
        "        grads = tape.gradient(loss, [W1, b1, W2, b2])\n",
        "        # Application des gradients pour mettre à jour les paramètres (descente de gradient)\n",
        "        optimizer.apply_gradients(zip(grads, [W1, b1, W2, b2]))\n",
        "    print(f\"Epoch {epoch+1} terminé\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eibhvcqspNbw",
        "outputId": "b4a912bd-9197-4f94-b7a2-69561764d816"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 terminé\n",
            "Epoch 2 terminé\n",
            "Epoch 3 terminé\n",
            "Epoch 4 terminé\n",
            "Epoch 5 terminé\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation du modele**"
      ],
      "metadata": {
        "id": "pcGA17PC7qmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for x_batch, y_batch in ds_test:\n",
        "    logits = model(x_batch)\n",
        "\n",
        "    # Pour chaque echantillon du batch, on selectionne l’indice de la classe avec la plus grande valeur de logit\n",
        "    preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "\n",
        "    y_batch = tf.cast(y_batch, tf.int32)\n",
        "\n",
        "    correct += tf.reduce_sum(tf.cast(preds == y_batch, tf.int32))\n",
        "    total += x_batch.shape[0]\n",
        "print(\"Accuracy :\", correct.numpy() / total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kFNLtJIpP2Y",
        "outputId": "213529c8-2f21-46d5-ec1d-044979781e36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9735\n"
          ]
        }
      ]
    }
  ]
}